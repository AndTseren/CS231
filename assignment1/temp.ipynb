{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run some setup code for this notebook.\n",
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the\n",
    "# notebook rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (50000, 32, 32, 3)\n",
      "Training labels shape:  (50000,)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the raw CIFAR-10 data.\n",
    "cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "\n",
    "# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_test, y_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 32, 32, 3)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 32, 32, 3)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 32, 32, 3)\n",
      "Test labels shape:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into train, val, and test sets. In addition we will\n",
    "# create a small development set as a subset of the training data;\n",
    "# we can use this for development so our code runs faster.\n",
    "num_training = 49000\n",
    "num_validation = 1000\n",
    "num_test = 1000\n",
    "num_dev = 500\n",
    "\n",
    "# Our validation set will be num_validation points from the original\n",
    "# training set.\n",
    "mask = range(num_training, num_training + num_validation)\n",
    "X_val = X_train[mask]\n",
    "y_val = y_train[mask]\n",
    "\n",
    "# Our training set will be the first num_train points from the original\n",
    "# training set.\n",
    "mask = range(num_training)\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "# We will also make a development set, which is a small subset of\n",
    "# the training set.\n",
    "mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "X_dev = X_train[mask]\n",
    "y_dev = y_train[mask]\n",
    "\n",
    "# We use the first num_test points of the original test set as our\n",
    "# test set.\n",
    "mask = range(num_test)\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]\n",
    "\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (49000, 3072)\n",
      "Validation data shape:  (1000, 3072)\n",
      "Test data shape:  (1000, 3072)\n",
      "dev data shape:  (500, 3072)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing: reshape the image data into rows\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "\n",
    "# As a sanity check, print out the shapes of the data\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[130.64189796 135.98173469 132.47391837 130.05569388 135.34804082\n",
      " 131.75402041 130.96055102 136.14328571 132.47636735 131.48467347]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEhdJREFUeJzt3W+oZdV5x/HvL0YT71Ucp0YzjFKN+CISmlEug2AJNmmDlYAKTdAX4gvJpG2ECukLsVAt9IUpVRFaDGMdMinWP42KQ5E2IimSN8arHccx0zZGpsnUYcagop0bmuo8fXH2wJ3J3euc85y997mT9fvAcM/d+6y9nrPveWafu5+71lJEYGb1+ci8AzCz+XDym1XKyW9WKSe/WaWc/GaVcvKbVcrJb1YpJ79ZpZz8ZpX66CyNJV0N3A+cAvxdRNxdev7i4mJsOHvDLF0OQNO3mL6JzVn+D1vX91/EvvvOuxw5cmSid2Q6+SWdAvwt8HvAAeBFSbsi4kdtbTacvYE/vPWPW/YWTmpLdpVeoZIZmWlXbtK+M9ls/eg4D/KHm75lNvmzfw5fate6J9HXt/7mgYmfO8vH/q3A6xHxRkT8EngUuHaG45nZgGZJ/s3Az1Z9f6DZZmYngVmSf60Ppr/yOUXSNknLkpaPHDkyQ3dm1qVZkv8AcMGq788H3jzxSRGxPSKWImJpcXFxhu7MrEuzJP+LwCWSLpJ0GnADsKubsMysb+m7/RHxgaRbgX9hVOrbERGvTdCy7XitLdTWpnRLvHSntHQnPQo723YV22RvK+ea/brqujIXySMW7/bndrXH0vN7YKY6f0Q8AzzTUSxmNiD/hZ9ZpZz8ZpVy8ptVyslvViknv1mlZrrbn9FWKok4WmjUUkpLl9GSpbm2XYWRPcXD9TJ4p7UeWQikjziGkwk/PUAneR6LvaXKkWv/nKd5Wb7ym1XKyW9WKSe/WaWc/GaVcvKbVWrwu/3ttzYTA3GSd1fbBgqNDSMxsKd4R7/4krOlgMSUVoU2w0WRbZQ9ZGZPeWc2/G4H9kzeyFd+s0o5+c0q5eQ3q5ST36xSTn6zSjn5zSo1bKkvolBLK5Xf1t7XRxmqWJnLDDBKTyWYrBFmesusJtODPvrqen68fDlvuL4m5Su/WaWc/GaVcvKbVcrJb1YpJ79ZpZz8ZpWaqdQnaT/wPvAh8EFELJWeH5Tm8Jt+ZFm5FDJgkSo7GV/X1bysPvrK/dBadR1iP2XFIdvN/gq6qPP/TkT8vIPjmNmA/LHfrFKzJn8A35P0kqRtXQRkZsOY9WP/lRHxpqRzgWcl/XtEPL/6Cc1/CtsAzjrrrBm7M7OuzHTlj4g3m6+HgaeArWs8Z3tELEXE0sLiwizdmVmH0skvaVHSmcceA18E9nYVmJn1a5aP/ecBT2k0+uyjwD9ExD+Pbzb9BJ7lZYum6wbyFba2iT+jcMTyyL3CzvUiPQRyuDhSXSXP/bDlvH7fIOnkj4g3gM92GIuZDcilPrNKOfnNKuXkN6uUk9+sUk5+s0oNvlZfxNGptpcP1r6ruB7f9D3lA+mhWefWSzmvB60hZmMvTKzafRkwtXDkxP36ym9WKSe/WaWc/GaVcvKbVcrJb1apge/2ty/XlZnDL7/MVKGvrgeQDKzzoSBDToXYx0ETJ6Q0UKv0nis2mz6M9ICxSfnKb1YpJ79ZpZz8ZpVy8ptVyslvViknv1mlBh/Y01oqyczhlxzYU1Kq5LR1WBz7kpxLMKutu3RfxYZdv4Iein0tEyWW50/MjXQadn6/2Q/mK79ZpZz8ZpVy8ptVyslvViknv1mlnPxmlRpb6pO0A/gScDgiPtNs2wg8BlwI7Ae+EhHvTNJh+9JbpeF007fJl9gyw/pyQwGzU+fl9LE+1cB1zOmjGLt3baVyXrKEnDohpfL37Cd4kiv/t4GrT9h2O/BcRFwCPNd8b2YnkbHJHxHPA2+fsPlaYGfzeCdwXcdxmVnPsr/znxcRBwGar+d2F5KZDaH3G36StklalrS8cmSl7+7MbELZ5D8kaRNA8/Vw2xMjYntELEXE0sLiQrI7M+taNvl3ATc3j28Gnu4mHDMbyiSlvkeAq4BzJB0A7gTuBh6XdAvwU+DLE/UWFCbwbF+uq31Szexsm90ur5WafHRwfUyPmZixMn1COi6Mlt46pVlcs7N0Fo6Zefe0rxo2+c95bPJHxI0tu74wcS9mtu74L/zMKuXkN6uUk9+sUk5+s0o5+c0qdXJM4FmeVXNNSq7jl5rXMRFfX4YtLXZdfsudRxXLaC1xFGddLfVW6Ku9/pZ7aekYJ+Mrv1mlnPxmlXLym1XKyW9WKSe/WaWc/GaVGrjUFwQto/dKtZBBJ/As6LikVxo8VqgadT5Ar5/yYMvozWQc+UGanQ8vLHSVe9O1lSP7fgv4ym9WKSe/WaWc/GaVcvKbVcrJb1apdTOwpzx4Z+19pcE75RhSu1BrHLkwStLVikQs+eWu1scMhZnTX3y/Je7Mj4uj+FZteQOV+pJmv277ym9WKSe/WaWc/GaVcvKbVcrJb1YpJ79ZpSZZrmsH8CXgcER8ptl2F/BV4K3maXdExDOzhTL9wJ7sMlnlKs/0haPs8bLlvPVTfOu2rjh9sbeRWEGrVEbLLuVVPhvTlwjLJd3Z68uTXPm/DVy9xvb7ImJL82/GxDezoY1N/oh4Hnh7gFjMbECz/M5/q6Q9knZIOruziMxsENnkfwC4GNgCHATuaXuipG2SliUtr6ysJLszs66lkj8iDkXEhxFxFHgQ2Fp47vaIWIqIpYWFhWycZtaxVPJL2rTq2+uBvd2EY2ZDmaTU9whwFXCOpAPAncBVkrYwqlLsB742cY+J5bpSS3wVQsgu5dXeKFm/Kh+0sC9RCOwjxK7lqm+p11Ys9ZXiKJYBuy3QZkaYTvPTHJv8EXHjGpsfmrgHM1uX/Bd+ZpVy8ptVyslvViknv1mlnPxmlRp+As/WZZy6LfWly4Bd18R6mGS0uExZ5oDpEBPlyB7WoMqU7UqxlyfbLIzOKw7TnH68ZalJJiVO5Cu/WaWc/GaVcvKbVcrJb1YpJ79ZpZz8ZpWaQ6mvRak011rXOFo4Xq6vlPTowsIhk3WvtupQ+SX3Ma4vMbowUQ4bd9DW110q2ZV66ricVxSFtfo6+Jn5ym9WKSe/WaWc/GaVcvKbVcrJb1apge/2R+pOe/vd/tzAnvygn5bt2UE4yRu25bExJ/Ecfsk76anxVsk5Evs4V+0vrd+fjK/8ZpVy8ptVyslvViknv1mlnPxmlXLym1VqkuW6LgC+A3wSOApsj4j7JW0EHgMuZLRk11ci4p1sIMUBE23z/vVQ6stID5opVbZyR2zfu07qeYWxKmMadtxf18cbc8zyfHxr7yyfqmEG9nwAfCMiPg1cAXxd0qXA7cBzEXEJ8FzzvZmdJMYmf0QcjIiXm8fvA/uAzcC1wM7maTuB6/oK0sy6N9Xv/JIuBC4DXgDOi4iDMPoPAji36+DMrD8TJ7+kM4AngNsi4r0p2m2TtCxpeeXILzIxmlkPJkp+SacySvyHI+LJZvMhSZua/ZuAw2u1jYjtEbEUEUsLi6d3EbOZdWBs8ksS8BCwLyLuXbVrF3Bz8/hm4OnuwzOzvkwyqu9K4CbgVUm7m213AHcDj0u6Bfgp8OV+QsxJVA4n2dlxIMkoEiXC8nJohb46npau3Ff3a3m1n/7SEl/dn6vygMXMa5v9BzM2+SPiB4WevjBzBGY2F/4LP7NKOfnNKuXkN6uUk9+sUk5+s0qtn+W6ihNdtozqyx4vXTZau13X1bCms1yzqXdkD5hUrOYNtxRWdgLPrNwR0/XqifjKb1YpJ79ZpZz8ZpVy8ptVyslvViknv1ml1lGpr70Y0lbl6XgezmNH7bjFOpk5sw+lgXGJw5VHMiZnO81Eki45Dls+nJWv/GaVcvKbVcrJb1YpJ79ZpZz8ZpVaN3f7i8sZFWama20z8LJQ7dZJIAPfbF43p3Go4407aKm/1n2FCliimxP5ym9WKSe/WaWc/GaVcvKbVcrJb1YpJ79ZpcaW+iRdAHwH+CRwFNgeEfdLugv4KvBW89Q7IuKZsT1mSiwtbcpjLNp3pstQqWWVCvpYuqpl13oZXpSfiq/jUUTp45UGoHW7r+NpC3/FJHX+D4BvRMTLks4EXpL0bLPvvoj46/7CM7O+TLJW30HgYPP4fUn7gM19B2Zm/Zrqd35JFwKXAS80m26VtEfSDklndxybmfVo4uSXdAbwBHBbRLwHPABcDGxh9MngnpZ22yQtS1peWflFByGbWRcmSn5JpzJK/Icj4kmAiDgUER9GxFHgQWDrWm0jYntELEXE0sLC6V3FbWYzGpv8Gt2KfAjYFxH3rtq+adXTrgf2dh+emfVlkrv9VwI3Aa9K2t1suwO4UdIWRlWk/cDXZgulNIJp+lpfFMpy5SLakMPfkgW40pDF1l2581GWaNnD6S2V0ZIHTLYrHTJTBiwecOomJ5rkbv8PWg45vqZvZuuW/8LPrFJOfrNKOfnNKuXkN6uUk9+sUifHBJ6ZCQ57KNe0yg6ZK77owuSkiWBay6Uzmf6Y6apcqVRWbJdqlYsju68llr5H9fnKb1YpJ79ZpZz8ZpVy8ptVyslvViknv1mlBi/1ZQo2mbKdPtL+/1oUymgqTo45+0iqEwIpdFU4H8UyYLf1oc6rTcn6Vfel22wcqc7GlAETbUphTMhXfrNKOfnNKuXkN6uUk9+sUk5+s0o5+c0qNXCpT7QVKTIllPJSfblSWWqIXnohvELJrodjDisz4q+PkZgdlz6zfSVKfWMiyTQ6jq/8ZpVy8ptVyslvViknv1mlnPxmlRp7t1/Sx4HngY81z/9uRNwp6SLgUWAj8DJwU0T8cvzxWvspxbDm9vIAnZLS4J1iw46tlzgGlL6hn1mirIdAsjquSHQxv98kV/7/BT4fEZ9ltBz31ZKuAL4J3BcRlwDvALfMHo6ZDWVs8sfI/zTfntr8C+DzwHeb7TuB63qJ0Mx6MdHv/JJOaVboPQw8C/wEeDciPmiecgDY3E+IZtaHiZI/Ij6MiC3A+cBW4NNrPW2ttpK2SVqWtLyyspKP1Mw6NdXd/oh4F/hX4Apgg6RjNwzPB95sabM9IpYiYmlhYWGWWM2sQ2OTX9InJG1oHp8O/C6wD/g+8AfN024Gnu4rSDPr3iQDezYBOyWdwug/i8cj4p8k/Qh4VNJfAv8GPDRZl20De7odCDJwIacH9dX6Bhyf08/ZTR4016zthEx+osYmf0TsAS5bY/sbjH7/N7OTkP/Cz6xSTn6zSjn5zSrl5DerlJPfrFIqjYzrvDPpLeC/mm/PAX4+WOftHMfxHMfxTrY4fjMiPjHJAQdN/uM6lpYjYmkunTsOx+E4/LHfrFZOfrNKzTP5t8+x79Ucx/Ecx/F+beOY2+/8ZjZf/thvVqm5JL+kqyX9h6TXJd0+jxiaOPZLelXSbknLA/a7Q9JhSXtXbdso6VlJP26+nj2nOO6S9N/NOdkt6ZoB4rhA0vcl7ZP0mqQ/abYPek4KcQx6TiR9XNIPJb3SxPEXzfaLJL3QnI/HJJ02U0cRMeg/4BRG04B9CjgNeAW4dOg4mlj2A+fMod/PAZcDe1dt+yvg9ubx7cA35xTHXcCfDnw+NgGXN4/PBP4TuHToc1KIY9Bzwmhc7hnN41OBFxhNoPM4cEOz/VvAH83Szzyu/FuB1yPijRhN9f0ocO0c4pibiHgeePuEzdcymggVBpoQtSWOwUXEwYh4uXn8PqPJYjYz8DkpxDGoGOl90tx5JP9m4Gervp/n5J8BfE/SS5K2zSmGY86LiIMwehMC584xllsl7Wl+Lej914/VJF3IaP6IF5jjOTkhDhj4nAwxae48kn+tqUbmVXK4MiIuB34f+Lqkz80pjvXkAeBiRms0HATuGapjSWcATwC3RcR7Q/U7QRyDn5OYYdLcSc0j+Q8AF6z6vnXyz75FxJvN18PAU8x3ZqJDkjYBNF8PzyOIiDjUvPGOAg8y0DmRdCqjhHs4Ip5sNg9+TtaKY17npOl76klzJzWP5H8RuKS5c3kacAOwa+ggJC1KOvPYY+CLwN5yq17tYjQRKsxxQtRjyda4ngHOiUaTMT4E7IuIe1ftGvSctMUx9DkZbNLcoe5gnnA38xpGd1J/AvzZnGL4FKNKwyvAa0PGATzC6OPj/zH6JHQL8BvAc8CPm68b5xTH3wOvAnsYJd+mAeL4bUYfYfcAu5t/1wx9TgpxDHpOgN9iNCnuHkb/0fz5qvfsD4HXgX8EPjZLP/4LP7NK+S/8zCrl5DerlJPfrFJOfrNKOfnNKuXkN6uUk9+sUk5+s0r9PyhPkvaabPDEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 3073) (1000, 3073) (1000, 3073) (500, 3073)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing: subtract the mean image\n",
    "# first: compute the image mean based on the training data\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "print(mean_image[:10]) # print a few of the elements\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(mean_image.reshape((32,32,3)).astype('uint8')) # visualize the mean image\n",
    "plt.show()\n",
    "\n",
    "# second: subtract the mean image from train and test data\n",
    "X_train -= mean_image\n",
    "X_val -= mean_image\n",
    "X_test -= mean_image\n",
    "X_dev -= mean_image\n",
    "\n",
    "# third: append the bias dimension of ones (i.e. bias trick) so that our SVM\n",
    "# only has to worry about optimizing a single weight matrix W.\n",
    "X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape, X_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 8.906335\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the naive implementation of the loss we provided for you:\n",
    "from cs231n.classifiers.linear_svm import svm_loss_naive\n",
    "import time\n",
    "\n",
    "# generate a random SVM weight matrix of small numbers\n",
    "W = np.random.randn(3073, 10) * 0.0001 \n",
    "\n",
    "loss, grad = svm_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "print('loss: %f' % (loss, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 3073)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3073, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 500)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = W.shape[1]\n",
    "num_train = X_dev.shape[0]\n",
    "num_classes, num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3073, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW = np.zeros(W.shape)\n",
    "dW.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = X_dev.dot(W)\n",
    "slices = y_dev.reshape(y_dev.shape[0], 1)\n",
    "true_scores = np.take_along_axis(scores, slices, axis=1)\n",
    "margins = scores - true_scores + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 1, 1, 1],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_positive_margins = np.greater(margins, 0).astype('int')\n",
    "print(idx_positive_margins.shape)\n",
    "idx_positive_margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 10, 10, 10,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10,  8, 10,  9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,  9, 10,\n",
       "       10,  9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10,  9, 10,  9,  4, 10,  9, 10, 10,  7, 10,  7, 10, 10,\n",
       "       10, 10, 10, 10,  6, 10, 10,  8, 10, 10, 10, 10, 10, 10, 10, 10,  9,\n",
       "       10,  7,  6, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,  6, 10,\n",
       "       10, 10, 10, 10,  7, 10, 10, 10, 10, 10, 10, 10,  8, 10, 10, 10, 10,\n",
       "       10,  4, 10, 10, 10, 10,  9,  9, 10, 10,  9,  9,  9, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10,  8, 10, 10, 10,  9, 10, 10, 10,  6, 10,  7,  8,\n",
       "       10, 10, 10,  7, 10, 10, 10,  9, 10, 10,  6, 10,  6, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10,  9, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10,  9, 10, 10, 10, 10, 10, 10, 10, 10,  3, 10, 10, 10,  2, 10,\n",
       "       10, 10, 10, 10,  9, 10, 10, 10, 10, 10, 10, 10, 10,  9, 10, 10, 10,\n",
       "       10,  8, 10, 10,  4,  9, 10, 10, 10,  3, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,  9, 10, 10, 10,\n",
       "       10, 10,  9, 10, 10, 10, 10, 10,  9, 10, 10, 10, 10, 10, 10, 10,  9,\n",
       "       10, 10,  9, 10, 10,  3,  9, 10, 10, 10,  9,  9, 10,  4, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,  9, 10,  6, 10,  9, 10,\n",
       "       10,  8, 10, 10, 10, 10, 10, 10, 10, 10, 10,  8, 10, 10, 10, 10, 10,\n",
       "       10, 10,  4, 10, 10, 10, 10, 10,  8, 10,  8, 10, 10, 10, 10, 10,  9,\n",
       "        4, 10, 10,  8, 10, 10,  5, 10,  9, 10,  7,  8, 10, 10, 10,  7,  8,\n",
       "       10, 10, 10,  9, 10, 10, 10, 10,  8, 10, 10, 10, 10, 10,  9, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10,  9, 10, 10,  9, 10, 10, 10,  9,  8,  5,\n",
       "       10, 10, 10, 10, 10,  9, 10, 10, 10, 10, 10, 10, 10,  9,  8, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,  7, 10, 10,  9, 10,\n",
       "       10, 10, 10,  4,  4, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,  8,  9,\n",
       "       10, 10, 10, 10, 10, 10,  9, 10, 10, 10, 10,  9, 10, 10, 10,  7, 10,\n",
       "       10, 10, 10, 10,  9, 10,  7, 10,  9, 10, 10, 10, 10, 10, 10, 10,  8,\n",
       "       10, 10, 10, 10, 10,  2, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_positive_margins.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  1, ...,  1,  1,  1],\n",
       "       [ 1,  1,  1, ...,  1,  1, -9],\n",
       "       [ 1,  1, -9, ...,  1,  1,  1],\n",
       "       ...,\n",
       "       [ 1,  1,  1, ...,  1, -9,  1],\n",
       "       [-1,  0,  0, ...,  0,  0,  0],\n",
       "       [ 1,  1,  1, ...,  1, -9,  1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_positive_margins[range(num_train), y_dev] -= idx_positive_margins.sum(axis=1)\n",
    "print(idx_positive_margins.shape)\n",
    "idx_positive_margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = X_dev.dot(W)\n",
    "true_scores_position = y_dev.reshape(y_dev.shape[0], 1)\n",
    "true_scores = np.take_along_axis(scores, true_scores_position, axis=1)\n",
    "margins = np.maximum(0, scores - true_scores + 1)\n",
    "margins_temp = np.copy(margins)\n",
    "margins_temp[margins_temp > 0] = 1\n",
    "print(margins_temp.shape)\n",
    "margins_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.take_along_axis(margins_temp, true_scores_position, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.take_along_axis(margins_temp, true_scores_position, axis=1) - margins_temp.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  1., -9.],\n",
       "       [ 1.,  1., -9., ...,  1.,  1.,  1.],\n",
       "       ...,\n",
       "       [ 1.,  1.,  1., ...,  1., -9.,  1.],\n",
       "       [-1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1., ...,  1., -9.,  1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.put_along_axis(margins_temp, true_scores_position, aa, axis=1)\n",
    "print(margins_temp.shape)\n",
    "margins_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36317809, 0.69368362, 0.78201763, ..., 1.10205728, 1.01441445,\n",
       "        0.89147809],\n",
       "       [0.81526851, 0.66764159, 1.15674151, ..., 0.73761358, 1.18057147,\n",
       "        1.        ],\n",
       "       [2.68659114, 1.36238618, 1.        , ..., 2.18133681, 2.58921817,\n",
       "        1.62404903],\n",
       "       ...,\n",
       "       [2.34394177, 1.91147534, 1.58178204, ..., 1.44810962, 1.        ,\n",
       "        2.37605751],\n",
       "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [1.47812216, 1.95083732, 1.19537046, ..., 1.14867103, 1.        ,\n",
       "        1.33917351]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.36317809,  0.69368362,  0.78201763, ...,  1.10205728,\n",
       "         1.01441445,  0.89147809],\n",
       "       [ 0.81526851,  0.66764159,  1.15674151, ...,  0.73761358,\n",
       "         1.18057147, -1.        ],\n",
       "       [ 2.68659114,  1.36238618, -1.        , ...,  2.18133681,\n",
       "         2.58921817,  1.62404903],\n",
       "       ...,\n",
       "       [ 2.34394177,  1.91147534,  1.58178204, ...,  1.44810962,\n",
       "        -1.        ,  2.37605751],\n",
       "       [-1.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.47812216,  1.95083732,  1.19537046, ...,  1.14867103,\n",
       "        -1.        ,  1.33917351]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.put_along_axis(margins, slices, -1, axis=1)\n",
    "margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  1., -1.],\n",
       "       [ 1.,  1., -1., ...,  1.,  1.,  1.],\n",
       "       ...,\n",
       "       [ 1.,  1.,  1., ...,  1., -1.,  1.],\n",
       "       [-1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  1.,  1., ...,  1., -1.,  1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margins[margins > 0] = 1\n",
    "margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 10, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margins[:,:, np.newaxis].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3073,500,1) (500,10,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-2a26727ee963>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmargins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3073,500,1) (500,10,1) "
     ]
    }
   ],
   "source": [
    "X_dev.transpose()[:,:, np.newaxis] * margins[:,:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dW = np.ones(W.shape)\n",
    "dW.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev.transpose().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev.transpose().dot(margins).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array(range(10))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not it.finished:\n",
    "    ix = it.multi_index\n",
    "    print(ix)\n",
    "    it.iternext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of cs231n.classifiers.linear_classifier failed: Traceback (most recent call last):\n",
      "  File \"/home/tseren/anaconda3/envs/cs231n/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 244, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/tseren/anaconda3/envs/cs231n/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 378, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/tseren/anaconda3/envs/cs231n/lib/python3.7/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/tseren/anaconda3/envs/cs231n/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 724, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 860, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 791, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/tseren/CS_231/assignment1/cs231n/classifiers/linear_classifier.py\", line 61\n",
      "    X_batch = X[]\n",
      "                ^\n",
      "SyntaxError: invalid syntax\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([11885, 11473,  3279, 35607,  5094, 29704, 41817, 20798, 48857,\n",
       "       16262, 44887, 15397, 28843, 19692, 11170, 43293, 12676,  7044,\n",
       "        9346, 25668, 42763, 20643, 33941, 12458,   171, 37762, 20841,\n",
       "       25627, 36379, 40381, 21042, 34334,  3452, 48150, 22420, 37221,\n",
       "       17188, 47319,  9051, 26004,  4807, 30329,  2959,  8600, 14757,\n",
       "       18044, 22910,  4597, 34391, 25612, 42770, 31961,  8770, 28330,\n",
       "       11090, 10634, 22033, 31685, 34777, 20575, 32159, 12209, 39666,\n",
       "       11034, 25637, 21606, 12672, 20927, 15190, 22165, 17242,  2390,\n",
       "       18534, 21569, 20177, 23440, 34288, 10956, 42898,  8075, 12178,\n",
       "       10099, 18705, 37375, 45423, 37523,  3664, 26949, 13519, 19954,\n",
       "        9810, 16223, 35451, 38710, 18637, 26620, 25791, 37003,  1560,\n",
       "       14574, 34156, 42655, 16199,  4823,  2948, 27789,  8376, 26485,\n",
       "       21827,  2813,  5382, 25028, 10087, 14685, 30470, 14712, 26093,\n",
       "       32951, 43202, 42470, 41619, 29645, 20784,  1420, 10862, 38892,\n",
       "       42980, 14707, 18993, 42851, 44717, 48346, 47240,  2371,  5247,\n",
       "        1214,  1736, 29183, 30804, 30596, 35394, 15359, 29171, 34756,\n",
       "       19748, 28259, 39085, 42239, 11987, 13310, 20940, 17778, 12404,\n",
       "        6812, 28152, 33717, 46734, 41608, 33148, 16184, 24663, 20803,\n",
       "       31694, 39476, 32524, 23815, 29021, 17547,  2849, 34646,    15,\n",
       "       19340, 20681, 24594,   493, 14571, 41044, 31826, 37400, 12390,\n",
       "       15144, 21663,  4245, 39669, 39296, 30400, 17059, 47960, 43084,\n",
       "       32195, 30951, 26226, 29010, 23311, 21654, 41755, 11138, 25968,\n",
       "       17291,  8431, 10337, 18560, 24567, 34205, 27201, 21607, 35039,\n",
       "       46730,  4933, 37414, 24231, 15056, 19600,  3678, 35646, 36724,\n",
       "        7371, 20106, 44826, 27436,   135,  7003, 17703, 42005, 22840,\n",
       "       25151, 46863, 31747, 26030, 19361,  2875,  8954, 35681, 48259,\n",
       "       29428,  2627, 11165, 36682,  5600, 47713, 10378,  2733, 40590,\n",
       "       36162, 13136, 11805, 36171, 26231, 10659, 13031, 31959, 25939,\n",
       "       26641, 21533, 31896,  2630])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "num_train = 49000\n",
    "idxs = np.random.choice(num_train, batch_size)\n",
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 3073)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 3073)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[idxs, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 7, 9, 0, 0, 5, 4, 7, 9, 0, 3, 5, 6, 9, 7, 1, 6, 8, 0, 8, 1,\n",
       "       1, 6, 2, 9, 8, 3, 1, 9, 8, 3, 1, 9, 3, 6, 2, 7, 3, 8, 8, 8, 0, 1,\n",
       "       7, 4, 6, 0, 5, 6, 8, 0, 2, 3, 6, 3, 9, 6, 4, 4, 1, 0, 0, 5, 7, 3,\n",
       "       4, 6, 9, 1, 7, 1, 7, 5, 6, 8, 6, 8, 8, 9, 0, 8, 4, 5, 0, 3, 4, 5,\n",
       "       8, 8, 9, 1, 2, 1, 4, 9, 7, 5, 0, 3, 6, 1, 5, 8, 2, 4, 0, 3, 3, 7,\n",
       "       9, 3, 8, 3, 2, 0, 1, 2, 4, 7, 2, 2, 3, 6, 5, 1, 6, 5, 3, 9, 4, 3,\n",
       "       6, 5, 1, 0, 1, 4, 1, 2, 5, 7, 1, 3, 8, 9, 7, 1, 6, 4, 5, 5, 9, 3,\n",
       "       7, 3, 5, 4, 0, 7, 5, 6, 1, 1, 3, 3, 3, 5, 1, 0, 9, 4, 7, 4, 1, 9,\n",
       "       9, 6, 9, 5, 2, 2, 8, 5, 4, 0, 7, 8, 3, 5, 1, 0, 3, 1, 2, 7, 4, 7,\n",
       "       2, 6, 8, 4, 0, 9, 2, 4, 0, 1, 7, 3, 6, 9, 7, 1, 8, 6, 1, 6, 7, 8,\n",
       "       8, 6, 9, 5, 5, 1, 8, 1, 5, 7, 2, 5, 2, 2, 8, 3, 5, 2, 8, 8, 2, 5,\n",
       "       0, 2, 7, 3, 5, 6, 9, 0, 1, 2, 2, 0, 0, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
